{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgcfv1rIAGN1XWNfg2jRGQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rad-Monk/TF-Notebooks/blob/main/in_context_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KU8eUl_xRjV"
      },
      "outputs": [],
      "source": [
        "pip install transformers datasets pdfminer.six torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    return extract_text(pdf_path)\n",
        "\n",
        "pdf_text = extract_text_from_pdf('/content/7. DS GRAPH.pdf')\n",
        "with open('document.txt', 'w') as f:\n",
        "    f.write(pdf_text)\n"
      ],
      "metadata": {
        "id": "HNiZojCTxdvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_text"
      ],
      "metadata": {
        "id": "7Jp7rQa_036h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text_preserve_paragraphs(text):\n",
        "    # Split the text into paragraphs based on double newlines\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "\n",
        "    # Clean each paragraph separately\n",
        "    cleaned_paragraphs = []\n",
        "    for paragraph in paragraphs:\n",
        "        # Replace multiple spaces within a paragraph with a single space\n",
        "        cleaned_paragraph = re.sub(r'\\s+', ' ', paragraph).strip()\n",
        "        cleaned_paragraphs.append(cleaned_paragraph)\n",
        "\n",
        "    # Join the cleaned paragraphs back together, preserving the double newline separation\n",
        "    return '\\n\\n'.join(cleaned_paragraphs)\n",
        "\n",
        "# Example usage:\n",
        "pdf_text = \"\"\"This is an example paragraph. It may contain multiple spaces.\n",
        "\n",
        "This is another paragraph.    With inconsistent spacing.\"\"\"\n",
        "\n",
        "cleaned_text = clean_text_preserve_paragraphs(pdf_text)\n",
        "print(cleaned_text)\n"
      ],
      "metadata": {
        "id": "PR4R9nkP05wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EFq3dChW1Hlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def split_into_paragraphs(text):\n",
        "#     return text.split('\\n\\n')\n",
        "\n",
        "# paragraphs = split_into_paragraphs(cleaned_text)\n"
      ],
      "metadata": {
        "id": "ptQptnwb1Iv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(paragraphs)"
      ],
      "metadata": {
        "id": "s-is565g1LP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def chunk_text(paragraphs, max_length=512):\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "    for paragraph in paragraphs:\n",
        "        paragraph_length = len(tokenizer.encode(paragraph, add_special_tokens=False))\n",
        "        if current_length + paragraph_length > max_length:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = []\n",
        "            current_length = 0\n",
        "        current_chunk.append(paragraph)\n",
        "        current_length += paragraph_length\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "    return chunks\n",
        "\n",
        "text_chunks = chunk_text(paragraphs)\n"
      ],
      "metadata": {
        "id": "SYnS9pyK1MZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks"
      ],
      "metadata": {
        "id": "DDMd950C1wqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline('question-answering', model='distilbert-base-uncased', tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "Yt6nlggs1xy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "id": "IsutD-9A2Lly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_answer(question, text_chunks):\n",
        "    best_answer = {\"score\": 0, \"answer\": \"\"}\n",
        "    for chunk in text_chunks:\n",
        "        result = qa_pipeline({\n",
        "            'question': question,\n",
        "            'context': text_chunks[1]\n",
        "        })\n",
        "        if result['score'] > best_answer['score']:\n",
        "            best_answer = result\n",
        "    return best_answer['answer']\n",
        "\n",
        "question = \"What is the main topic of the document?\"\n",
        "answer = find_answer(question, text_chunks)\n",
        "print(answer)\n"
      ],
      "metadata": {
        "id": "X4IINpcb13e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nb8RmXhd17Jn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}